:toc:
:source-highlighter: highlightjs

== elastic stack

=== elasticsearch

==== 使用 xpack

.elasticsearch.yml
[source,yml]
----
xpack.security.enabled: true
xpack.security.transport.ssl.enabled: true
----

==== 节点间 ssl 通信配置

.证书生成
[source,shell]
----

----

.elasticsearch.yml
[source,yml]
----
# 配置使用PKCS#12格式的证书
xpack.security.transport.ssl.verification_mode: certificate #认证方式使用证书
xpack.security.transport.ssl.keystore.path: certs/elastic-certificates.p12
xpack.security.transport.ssl.truststore.path: certs/elastic-certificates.p12

#配置使用 -pem生成PEM格式的证书
xpack.security.transport.ssl.verification_mode: certificate 
xpack.security.transport.ssl.key: /home/es/config/node01.key # 私钥
xpack.security.transport.ssl.certificate: /home/es/config/node01.crt # 证书
xpack.security.transport.ssl.certificate_authorities: [ "/home/es/config/ca.crt" ]
----

.告知 es 证书口令
[source,shell]
----
# 如果你生成的node证书设置了 password，那么需要把 password 加入到 elasticsearch 的keystore
# p12 格式
bin/elasticsearch-keystore add xpack.security.transport.ssl.keystore.secure_password
bin/elasticsearch-keystore add xpack.security.transport.ssl.truststore.secure_password

# PEM格式
bin/elasticsearch-keystore add xpack.security.transport.ssl.secure_key_passphrase
----

==== 开启 basic 

.elasticsearch.yml
[source,yml]
----
http.cors.enabled: true
http.cors.allow-origin: "*"
http.cors.allow-headers: Authorization
----

.进入 es docker 容器内执行命令，设置密码
[source,shell]
----
> elasticsearch-setup-passwords interactive

Initiating the setup of passwords for reserved users elastic,apm_system,kibana,kibana_system,logstash_system,beats_system,remote_monitoring_user.
You will be prompted to enter passwords as the process progresses.
Please confirm that you would like to continue [y/N]y


Enter password for [elastic]:
Reenter password for [elastic]:
Passwords do not match.
Try again.
Enter password for [elastic]:
Reenter password for [elastic]:
Enter password for [apm_system]:
Reenter password for [apm_system]:
Enter password for [kibana_system]:
Reenter password for [kibana_system]:
Enter password for [logstash_system]:
Reenter password for [logstash_system]:
Passwords do not match.
Try again.
Enter password for [logstash_system]:
Reenter password for [logstash_system]:
Enter password for [beats_system]:
Reenter password for [beats_system]:
Enter password for [remote_monitoring_user]:
Reenter password for [remote_monitoring_user]:
Changed password for user [apm_system]
Changed password for user [kibana_system]
Changed password for user [kibana]
Changed password for user [logstash_system]
Changed password for user [beats_system]
Changed password for user [remote_monitoring_user]
Changed password for user [elastic]
----

用户管理相关 api

GET _security/user


==== 使用 searchguard 插件


=== 使用时的优化

==== Index

1. 关闭索引

2. 只读索引

3. 滚动索引

4. 分片数需要建索引前确定好，后续无法修改，新索引可以通过修改索引模板，新索引才能生效，旧索引只能迁移数据到新索引，即重建索引

5. 副本数可以动态修改，如果服务器资源有限，可以先选择设置副本数=0

==== Mapping

1. 某些字段不做索引

2. 正确设置 string 字段类型：不做分词索引的一律使用 keyword

==== Document

1. 新增文档，id 如果可以的话使用 es 自动生成的 id, 可以提高写入性能（如果使用自定义的id,写入时会检验是否冲突）

==== 参数

1. 锁内存 bootstrap.mlockall: true

=== API

.查看资源使用情况
[source]
----
http://node.thingsmatrix.co:31920/_cat/nodes?v&h=http,version,jdk,disk.total,disk.used,disk.avail,disk.used_percent,heap.current,heap.percent,heap.max,ram.current,ram.percent,ram.max,master
----

query_string vs multi_match



=== 安装使用 elasticsearch-head


1. git clone https://github.com/mobz/elasticsearch-head.git

2. scoop install npm -g

3. npm install yarn -g

4. cd elasticsearch-head && yarn install

5. yarn run start

6. 浏览器打开 localhost:9100，或者 localhost:9100/?auth_user=elastic&auth_password=xxx


=== 脚本

批量写入大量数据::

1. 将 index 设置为只读
2. 索引 setting 关闭定时 refresh 或者 bulk?refresh=false, 全部写完再手动refresh POST <index>/_refresh
3. `curl -XPUT 'http://elastic:xxx@node.thingsmatrix.co:31920/_bulk' -H "Content-Type: application/json" --data-binary @order_test_data.json`

=== 分页

1. 在7.0版发布之前，hits.total始终用于表示符合查询条件的文档的实际数量。在Elasticsearch 7.0版中，如果匹配数大于10,000，则不会计算hits.total。 这是为了避免为给定查询计算精确匹配文档的不必要开销。 我们可以通过将 `track_total_hits = true` 作为请求参数来强制进行精确匹配的计算。


2. 索引默认只支持offset+size<=10000，超过则会报错，可以修改 settings `max_result_window=1000000` 增大限制


=== 排错

错误：FORBIDDEN/12/index read-only / allow delete (api)
 
原因： 当系统内存或存储超过水位线时，会将索引的 settings index.blocks.read_only_allow_delete = false, 可以通过 GET _all/_settings 或 GET 索引名/_settings 查看

解决： 增大或回收系统资源，PUT 索引名/_settings -d {"index.blocks.read_only_allow_delete": null or false}

